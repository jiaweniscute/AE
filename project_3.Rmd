---
title: "Project_3"
author: "Ng Jia Wen"
date: "7 August 2017"
output: html_document
---

```{r}
setwd("~/School/Analytical Edge/Project")
library(mlogit) 
library(ModelMetrics)
library(glmnet)
library(caret)


safety<- read.csv('train.csv')

train_rf <- subset(safety,Task <= 12)
test_rf <- subset(safety,Task >12)

train <-  mlogit.data(subset(safety,Task<=12),
                  shape ='wide',
                  choice = 'Choice',
                  sep = '',
                  varying = c(4:83), 
                  alt.levels = c("Ch1","Ch2","Ch3","Ch4"),id.var = 'Case')

test <-  mlogit.data(subset(safety,Task > 12),
                  shape ='wide',
                  choice = 'Choice',
                  sep = '',
                  varying = c(4:83), 
                  alt.levels = c("Ch1","Ch2","Ch3","Ch4"),
                  id.var = 'Case') 

ActualChoice <- subset(safety, Task > 12)[,"Choice"]
```




```{r}

# probitmodel <-  mlogit(Choice ~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price-1,data = train,probit = TRUE)
# probit_pred <- predict(probitmodel,newdata = test,probability = TRUE)
# probit_mll <- mlogLoss(ActualChoice,probit_pred)
# 
# probitmodel_i <-  mlogit(Choice ~CC+GN+NS+BU+FA+LD+BZ+FC+FP+RP+PP+KA+SC+TS+NV+MA+LB+AF+HU+Price,data = train,probit = TRUE)
# probit_pred_i <- predict(probitmodel_i,newdata = test,probability = TRUE)
# probit_mll_i <- mlogLoss(ActualChoice,probit_pred_i)
# 
# 
# probitmodel2 <-  mlogit(Choice ~Price|Urb,data = train,probit = TRUE)
# probit_pred2 <- predict(probitmodel2,newdata = test,probability = TRUE)
# probit_mll2 <- mlogLoss(ActualChoice,probit_pred2)
# 
# 
# mixedlogitmodel2 <-  mlogit(Choice ~Price|Urb,data = train,panel = TRUE, rpar = c(Price = 'n', Urb = 'n') )
# mixedlogit_pred2 <- predict(mixedlogit_pred2,newdata = test,probability = TRUE)
# mixedlogit2 <- mlogLoss(ActualChoice,mixedlogit2)

# probitmodel_2 <-  mlogit(Choice ~NV+BU+FP+SC+Price-1|
#                         segment+income+ppark+age+miles+educ+Urb+year+gender+region+night,data = train,probit = TRUE)
# probit_pred_2 <- predict(probitmodel_2,newdata = test,probability = TRUE)
# probit_mll_2 <- mlogLoss(ActualChoice,probit_pred_2)

mlogloss <- function(data, lev = NULL, model = NULL) {
  logloss_val <- logLoss(y_pred = data$pred, y_true = data$Choice, positive = lev[1])
  c(mlogloss = logloss_val)
}

control <- trainControl(method ='cv',savePredictions = T, classProbs = T)


## Random Forest
set.seed(1)
fit.rf <- train(Choice~.-Case-No-Task-Ch1-Ch2-Ch3-Ch4, data=train_rf, method="rf", trControl=control)

pred.rf <- predict(fit.rf, newdata = test_rf, type = 'prob')
mlogLoss(test_rf[,'Choice'],pred.rf)

# control <- trainControl(method="repeatedcv", number=5, repeats=3)
# CART
set.seed(7)
fit.cart <- train(Choice~., data=PimaIndiansDiabetes, method="rpart", trControl=control)
# LDA
set.seed(7)
fit.lda <- train(diabetes~., data=PimaIndiansDiabetes, method="lda", trControl=control)
# SVM
set.seed(7)
fit.svm <- train(diabetes~., data=PimaIndiansDiabetes, method="svmRadial", trControl=control)
# kNN
set.seed(7)
fit.knn <- train(diabetes~., data=PimaIndiansDiabetes, method="knn", trControl=control)
# Random Forest
set.seed(7)
fit.rf <- train(Choice~.-Ch1-Ch2-Ch3-Ch4-Task-Case-No, data=train_rf, method="rf", trControl=control)
# collect resamples
results <- resamples(list(CART=fit.cart, LDA=fit.lda, SVM=fit.svm, KNN=fit.knn, RF=fit.rf))
```

```{r}
```{r}

LogLosSummary <- function (data, lev = NULL, model = NULL) {
  LogLos <- function(actual, pred, eps = 1e-15) {
    stopifnot(all(dim(actual) == dim(pred)))
    pred[pred < eps] <- eps
    pred[pred > 1 - eps] <- 1 - eps
    -sum(actual * log(pred)) / nrow(pred) 
  }
  if (is.character(data$obs)) data$obs <- factor(data$obs, levels = lev)
  pred <- data[, "pred"]
  obs <- data[, "obs"]
  isNA <- is.na(pred)
  pred <- pred[!isNA]
  obs <- obs[!isNA]
  data <- data[!isNA, ]
  cls <- levels(obs)

  if (length(obs) + length(pred) == 0) {
    out <- rep(NA, 2)
  } else {
    pred <- factor(pred, levels = levels(obs))
    require("e1071")
    out <- unlist(e1071::classAgreement(table(obs, pred)))[c("diag",                                                                                                                                                             "kappa")]

    probs <- data[, cls]
    actual <- model.matrix(~ obs - 1)
    out2 <- LogLos(actual = actual, pred = probs)
  }
  out <- c(out, out2)
  names(out) <- c("Accuracy", "Kappa", "LogLoss")

  if (any(is.nan(out))) out[is.nan(out)] <- NA 

  out
}

set.seed(1)
control <- trainControl(method ='repeatedcv', number = 10, repeats = 3, savePredictions = T, classProbs = T, search = "grid",summaryFunction = LogLosSummary)
tunegrid <- expand.grid(.mtry=c(1:15))

Sys.time()
rf_gridsearch <- train(Choice~Price1+Price2+Price3+segment+night+ppark+age+region+miles+educ+Urb+year+gender+NV1+NV2+SC2+FP3+BU3+AF2, data=train, method="rf", trControl=control, tuneGrid = tunegrid,metric = "LogLoss")

Sys.time()
print(rf_gridsearch)
plot(rf_gridsearch)



```